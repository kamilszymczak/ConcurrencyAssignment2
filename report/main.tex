\title{\bf Operating Systems \\\& \\Concurrency \\Assignment-2\\ }
\author{
	
	Hudson Zhong | \texttt{hsz1@hw.ac.uk}\\
	Kamil Symczak | \texttt{ks83@hw.ac.uk}\\
	Lewis Wilson | \texttt{lw52@hw.ac.uk}\\
	Saad Badshah | \texttt{sb135@hw.ac.uk}\\
	Sam Fay-Hunt | \texttt{sf52@hw.ac.uk}
}

\documentclass[11pt]{article}
\usepackage[table]{xcolor}
\usepackage[]{geometry} 
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{dashrule}
\usepackage{float}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mwe}
\usepackage[markcase=noupper% remove the uppercasing
]{scrlayer-scrpage}
\usepackage{caption}

\hypersetup{ linktoc=all}
\graphicspath{ {./images/} }
\ofoot*{\pagemark}
\ifoot*{Operating Systems \& Concurrency - Assignment 2}
\ohead{}

\begin{document}
\maketitle
\tableofcontents
\thispagestyle{empty}
\pagebreak
\setcounter{page}{1}
\section{Comparison of Different Methods Used to Achieve Synchronization}

\subsection{Efficiency Vs. responsiveness}


When developing our solutions we have experienced significant differences between the results on a system by system basis. We have selected a single system to run all the tests on, so that their relative performance in that environment can be compared. The system in question has a 4 core 4.5Ghz i7 processor, 16GB of DDR4 RAM and is running the latest version of Windows 10. It is important to emphasize that the tests are not representative of anything beyond the system they ran on.

The table below shows the average time in seconds to complete 5 runs of the tests, for each of the sync classes. A description of each test and the full test results have been provided in the appendix: 

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}
\begin{table}[H]
\caption{}
\label{tab:my-table}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Test Name & Atomic & Intrinsic & Extrinsic & Semaphore & Result    \\ \hline
1A        & 23.364 & 8.393     & 47.181    & 9.741     & Intrinsic \\ \hline
1B        & 0.815  & 0.690     & 0.719     & 1.146     & Intrinsic \\ \hline
2A        & 0.127  & 0.124     & 0.125     & 0.107     & Semaphore \\ \hline
2D        & 2.040  & 1.738     & 1.753     & 2.796     & Intrinsic \\ \hline
3A        & 1.794  & 2.630     & 2.624     & 2.624     & Atomic    \\ \hline
\end{tabular}
\end{table}


Thus a direct ranking based purely on an efficiency perspective results in the following ranking: 

\begin{enumerate}
	\item Intrinsic
	\item Semaphore \& Atomic
	\item Extrinsic
\end{enumerate}




\pagebreak
\subsection{Readability}
discussion about  Readability (about half a page)

Below is a discussion by the team about the readability of the four classes: \\

\textbf{AtomicSync} - The team thought overall the code was well formatted and made good use of white space. Members found that conceptually busy waits are easier to follow than some of the other implementations. Members commented on the fact when reading the code, compare and set could be potentially misleading if you have not read and correctly understood the documentation.\\

\textbf{IntrinsicSync} - The team agreed method names could be improved - “call, put, take”. Members found it easy to understand where only a single thread executes code and where concurrency is permitted. Members commented on the finish method stating that it was well commented as well as the logic being easy to understand. \\

\textbf{ExtrinsicSync} - The team agreed like in IntrinsicSync method names could be improved “put and take”. Members also commented on the fact time needed to be spent on familiarising yourself with the .await() and .signalAll() functionally to understand the implementation. Members found the code well formatted and thought that it made good use of comments. \\

\textbf{SemaphoreSync} - The team thought as a whole that Semaphore Sync was the most complex implementation out of all the classes, with it taking the largest amount of time to familiarise with the implementation. Members commented on the fact that the solution could perhaps be simplified if given more time.  \\

The teams ranking of the classes based on readability and sharing code within by team: 

\begin{enumerate}
	\item AtomicSync
	\item IntrinsicSync
	\item ExtrinsicSync
	\item SemaphoreSync
\end{enumerate}

\pagebreak
\subsection{Error-proneness}
discussion about Error-proneness (about half a page)

\newpage
\appendix
\section{Test description}
\textbf{Test 1A description:} A stress test that creates 10,000 threads that run phase one. We wait till all threads terminate (or they timeout via our built in timeout feature) and count the threads that terminated. We then check that the number of threads terminated is equal to the number of threads we expected to terminate (the largest multiple of created threads).\\

\textbf{Test 1B description:} Same logic as Test 1A but runs multiple tests with a different number of threads using a parameterized input. In the test we have used the following input : {0, 1, 3, 4, 7, 8, 10, 12, 25, 36, 50, 100, 123, 523}. This test is predominantly testing the edge cases of the specification. \\

\textbf{Test 2A description :} We created 10 threads that run phase two. We assign the first half of threads to a group with id 0 and the second half to a group with id 1. We wait till threads in each group terminate and count them. We then expect the number of threads terminated in each group to equal our expected number of threads to be terminated. \\


\textbf{Test 2D description:}
\\

\textbf{Test 3A description:}
\\


\section{Readability ranking table}

\end{document}
